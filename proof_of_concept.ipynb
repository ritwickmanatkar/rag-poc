{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9499d436",
   "metadata": {},
   "source": [
    "# 1. Installing the required library. \n",
    "TODO: Add a package manager like poetry in the final version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec9c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca51c902",
   "metadata": {},
   "source": [
    "# 2. Resolving the OpenAI API access requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dad682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from config import OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b39b7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f8cbf",
   "metadata": {},
   "source": [
    "# 3. Resolving the Langchain/Langsmith access requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd16a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import LANGSMITH_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58b275a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = LANGSMITH_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e6f88",
   "metadata": {},
   "source": [
    "# 4. Building a Rudimentary RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "672170db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf2cb21",
   "metadata": {},
   "source": [
    "### 4.1. Loading a small chunk of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d088f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilized the information on the webpage of my Winter Quarter class on Scalable Data Systems.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://hao-ai-lab.github.io/dsc204a-w24/syllabus/\",\n",
    "               \"https://hao-ai-lab.github.io/dsc204a-w24/resources/\"),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"main-content\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "info = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c967bfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n Syllabus\\n        \\n        \\n      \\n\\n Table of Contents\\n        \\n        \\n      \\n\\nSyllabus \\nLogistics\\nCourse Content and Format \\nLectures\\n3 Programming Assignments (PAs)\\nExams\\nScribe notes\\nReading Su'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking information scraped from the \"Syllabus\" page.\n",
    "info[0].page_content[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfc77120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n Resources\\n        \\n        \\n      \\n\\n Table of Contents\\n        \\n        \\n      \\n\\nBook\\nAdditional Books\\nPast Offerings\\nMaterials \\nStudent Materials Folder\\nResources on Ray\\nRelated Documentation and '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Checking information scraped from the \"Resources\" page.\n",
    "info[1].page_content[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c868ee",
   "metadata": {},
   "source": [
    "### 4.2. Splitting data into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02cfda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RecursiveCharacterTextSplitter(chunk_size=999, chunk_overlap=200).split_documents(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "893fcf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of splits made: 18\n",
      "\n",
      "-------------------------------------------------- \n",
      "\n",
      "First split: \n",
      " page_content='Syllabus\\n        \\n        \\n      \\n\\n Table of Contents\\n        \\n        \\n      \\n\\nSyllabus \\nLogistics\\nCourse Content and Format \\nLectures\\n3 Programming Assignments (PAs)\\nExams\\nScribe notes\\nReading Summary\\nParticipation\\n\\n\\nPre-requisites\\nGrading \\nComponents\\nCutoffs\\n\\n\\nClassroom Rules\\n\\n\\n\\nThe course is organized into four parts, covering the following topics.\\n\\nFoundations of Data Systems: Data models, big data storage and retrieval, and how to encode information when you store data.\\nScaling Distributed Systems: Cluster, cloud, edge, network, replication, partition, consistency, ACID.\\nData Processing and Programming model: Batch processing, stream processing, MapReduce, Hadoop, Spark, Ray.\\nMachine Learning Systems: GPUs, TensorFlow, PyTorch, data and model parallelism, LLM training and serving.' metadata={'source': 'https://hao-ai-lab.github.io/dsc204a-w24/syllabus/'}\n",
      "\n",
      "-------------------------------------------------- \n",
      "\n",
      "Last split: \n",
      " page_content='University Health Services\\nUHS Counseling and Psychological Services (CAPS)\\nOffice For Students with Disabilities\\nOffice of Student Advocacy\\nBasic Needs Center\\nMental Health Resources Guide' metadata={'source': 'https://hao-ai-lab.github.io/dsc204a-w24/resources/'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"No of splits made: {len(splits)}\")\n",
    "print(f\"\\n{'-'*50} \\n\")\n",
    "print(f\"First split: \\n {splits[0]}\")\n",
    "print(f\"\\n{'-'*50} \\n\")\n",
    "print(f\"Last split: \\n {splits[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bfadcd",
   "metadata": {},
   "source": [
    "### 4.3. Generating Embeddings: \n",
    "Since I intend to use GPT3-Turbo model for this POC, I will be using the OpenAIEmbeddings generator function.\n",
    "\n",
    "I will get back a vectorstore which can be used as a retriever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1e53d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dded546",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31668081",
   "metadata": {},
   "source": [
    "### 4.4. RAG Prompt:\n",
    "Using a community template for the RAG prompt.<br> \n",
    "Link: https://smith.langchain.com/hub/rlm/rag-prompt?organizationId=d1f8dd50-f543-5244-a666-0e199c97fd76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c87d43b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb1924",
   "metadata": {},
   "source": [
    "### 4.5. Setting the LLM:\n",
    "I have decided to use GPT 3.5 turbo for this POC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85f27f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting temperature as 0 to curb creative output generation.\n",
    "# TODO: Explore other GPT base versions like davinci & babbage.\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18446a8",
   "metadata": {},
   "source": [
    "### 4.6. Setting up Post-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbf77cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(info):\n",
    "    return \"\\n\\n\".join(document.page_content for document in info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674edf24",
   "metadata": {},
   "source": [
    "### 4.7. Building an RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fa3d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3987b3",
   "metadata": {},
   "source": [
    "### 4.8. Tests v.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2370d67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The course consists of 50-minute lectures held three times a week in person, with attendance encouraged but not mandatory. There are scribe notes and reading summaries required for each lecture, along with 3 programming assignments. The course covers topics such as data systems foundations, scaling distributed systems, data processing, and machine learning systems.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test v.0.0:\n",
    "# Checking a topic present in the info(context). It is a header topic. \n",
    "rag_chain.invoke(\"What is the course content and format?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e3485",
   "metadata": {},
   "source": [
    "<b>Assessment:</b><br>\n",
    "Checking this link: https://hao-ai-lab.github.io/dsc204a-w24/syllabus/#course-content-and-format\n",
    "<br>As we can see the main information is mostly well summarized but as a student who has taken the course, I know that for:<br><br>\n",
    "<i>\"scribe notes and reading summaries required for each lecture\"</i><br><br>\n",
    "We do not have the accurate information. \n",
    "<ul><li>We had readings assigned for each lecture but the reading summaries were assigned once a week.\n",
    "<li>Further, the scribe notes were prepared for each lecture by a group of 2-3 rotating student groups.</ul><br>\n",
    "<b>Possible Adjustment:</b><br> \n",
    "<ul>\n",
    "    <li> Return the source links/documents. Additionally, provide a disclaimer.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32a37991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "\n",
      "The course consists of 50-minute lectures held three times a week in person, with attendance encouraged but not mandatory. There are scribe notes and reading summaries required for each lecture, along with 3 programming assignments. The course covers topics such as data systems, distributed systems, data processing, and machine learning systems.\n",
      "\n",
      "DISCLAIMER: LLM Generated Summary. Summary is generated from the sources seen below.\n",
      "['https://hao-ai-lab.github.io/dsc204a-w24/syllabus/']\n"
     ]
    }
   ],
   "source": [
    "# Test v.0.1\n",
    "# Adding the Link to the response.\n",
    "altered_rag_chain = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=altered_rag_chain)\n",
    "\n",
    "result = rag_chain_with_source.invoke(\"What is the course content and format?\")\n",
    "\n",
    "# TODO: Optimize\n",
    "relevant_docs = set()\n",
    "for doc in result.get('context'):\n",
    "    relevant_docs.add(doc.metadata.get('source'))\n",
    "\n",
    "print(f\"Answer:\\n\\n{result.get('answer')}\\n\\nDISCLAIMER: LLM Generated Summary. Summary is generated from the sources seen below.\\n{list(relevant_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b7c6c2",
   "metadata": {},
   "source": [
    "<b>Assessment:</b><br>\n",
    "<ul>\n",
    "    <li> Generated Data might still be misleading. Root cause not addressed.\n",
    "    <li> Langchain Runtime Comparison shows that this type of query is slower. (v.0.0 = 1.88s and v.0.1 = ~2.25s)\n",
    "    <li> Disclaimer might be problematic.\n",
    "    <li> If there are many sources returned then processing step might be slow. Something similar to lazy loading required? \n",
    "</ul>\n",
    "<b>Possible Adjustment:</b><br> \n",
    "<ul>\n",
    "    <li> Reseaeched and found a Vector Similarity Check that can be performed. \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd1743",
   "metadata": {},
   "source": [
    "### 4.9. Vector Similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a63217fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 ms ± 47.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "(Document(page_content='Course Content and Format\\n        \\n        \\n      \\n\\n Lectures\\n        \\n        \\n      \\nThe class meets 3 times a week for 50-minute lectures in person.\\n\\nAttending the lectures is not mandatory but highly encouraged. All lectures will be automatically podcast here afterward.\\nThere will be scribe notes required for each lecture. Students should form groups of 2 - 4 people and sign up one slot. See details below.\\nThere will be reading summary required per week. Everyone needs to submit their reading summary. See details below.\\nWe will use Piazza for asynchronous discussions and questions.\\n\\n\\n 3 Programming Assignments (PAs)\\n        \\n        \\n      \\n\\nSee the assignments page for updates on the PA schedule and details.\\nThere are no late days for the PAs. Plan your work accordingly.\\n\\n\\n Exams', metadata={'source': 'https://hao-ai-lab.github.io/dsc204a-w24/syllabus/'}), 0.3072233498096466)\n",
      "\n",
      "\n",
      "(Document(page_content='Syllabus\\n        \\n        \\n      \\n\\n Table of Contents\\n        \\n        \\n      \\n\\nSyllabus \\nLogistics\\nCourse Content and Format \\nLectures\\n3 Programming Assignments (PAs)\\nExams\\nScribe notes\\nReading Summary\\nParticipation\\n\\n\\nPre-requisites\\nGrading \\nComponents\\nCutoffs\\n\\n\\nClassroom Rules\\n\\n\\n\\nThe course is organized into four parts, covering the following topics.\\n\\nFoundations of Data Systems: Data models, big data storage and retrieval, and how to encode information when you store data.\\nScaling Distributed Systems: Cluster, cloud, edge, network, replication, partition, consistency, ACID.\\nData Processing and Programming model: Batch processing, stream processing, MapReduce, Hadoop, Spark, Ray.\\nMachine Learning Systems: GPUs, TensorFlow, PyTorch, data and model parallelism, LLM training and serving.', metadata={'source': 'https://hao-ai-lab.github.io/dsc204a-w24/syllabus/'}), 0.3243269920349121)\n",
      "\n",
      "\n",
      "(Document(page_content='A major component of this course is hands-on Python programming to implement data exploration, data preparation, distributed deep learning training and inference, and model selection pipelines on large real-world data using popular libraries (e.g., Ray, PyTorch) and cloud resources (e.g., AWS/GCP).\\n\\n Logistics\\n        \\n        \\n      \\n\\nLectures: MWF 10:00 AM - 10:50 AM.\\nLocation: PCYNH 122.\\nInstructor: Hao Zhang; Office: HDSI 440.\\n\\n\\n Course Content and Format\\n        \\n        \\n      \\n\\n Lectures\\n        \\n        \\n      \\nThe class meets 3 times a week for 50-minute lectures in person.', metadata={'source': 'https://hao-ai-lab.github.io/dsc204a-w24/syllabus/'}), 0.3746759593486786)\n",
      "\n",
      "\n",
      "(Document(page_content='Exams\\n        \\n        \\n      \\n\\nTo make your life easier: There is NO midterm. As an alternative, we ask for scribe notes and reading summary.\\nThere will be a final exam. The final exam will be held as a Canvas Quiz.\\nTentative date: Friday, March 22, 8 - 11 am, PT.\\nThe exams will have primarily multiple choice questions (MCQ). Quantitative/longer problems wil exist but only the final answer may need to be selected. Some questions will have partial credits.\\nThe guideline for time per question is a max of 1min per point. The points of each question will be calibrated accordingly.\\nIf you miss an exam, you will get no credit for it, unless you notify the instructor in advance with a university approved reason and receive a makeup exam slot.\\nThe final exam is open books/Web/etc. The only requirement is you should neither give nor receive help from anyone by any means.', metadata={'source': 'https://hao-ai-lab.github.io/dsc204a-w24/syllabus/'}), 0.395754337310791)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%timeit vectorstore.similarity_search_with_score(\"What is the course content and format?\")\n",
    "\n",
    "similar_docs = vectorstore.similarity_search_with_score(\"What is the course content and format?\")\n",
    "for doc in similar_docs:\n",
    "    print(doc)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc9256",
   "metadata": {},
   "source": [
    "<b>Assessment:</b><br>\n",
    "<ul>\n",
    "    <li> + Seems pretty fast. Faster the previous LLM based querying. \n",
    "    <li> + Also has a method that performs the search with a score.\n",
    "    <li> - Cosine distance is used which has pitfalls as mentioned here: https://marketbrew.ai/a/cosine-similarity#what-are-the-potential-challenges-or-limitations-of-using-cosine-similarity-in-certain-scenarios\n",
    "</ul>\n",
    "<b>Possible Adjustment:</b><br> \n",
    "<ul>\n",
    "    <li> Discuss with Prof. how to best overcome this. \n",
    "    <li> Combination method?\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd82409",
   "metadata": {},
   "source": [
    "### 4.10. Tests v.0 contd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea7479d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chemistry is the study of matter, its properties, composition, and interactions. It involves understanding the structure of atoms and molecules, as well as the changes they undergo. Chemistry is a fundamental science that plays a crucial role in various fields such as medicine, engineering, and environmental science.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test v.0.2:\n",
    "# Checking a topic absent in the info(context). \n",
    "rag_chain.invoke(\"What is Chemistry?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2013bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "\n",
      "Chemistry is the study of matter, its properties, composition, and interactions. It involves understanding the structure of atoms and molecules, as well as the changes they undergo. Chemistry is a fundamental science that plays a crucial role in various fields such as medicine, engineering, and environmental science.\n",
      "\n",
      "DISCLAIMER: LLM Generated Summary. Summary is generated from the sources seen below.\n",
      "['https://hao-ai-lab.github.io/dsc204a-w24/syllabus/']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError(\"Failed to post https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPSConnectionPool(host='api.smith.langchain.com', port=443): Read timed out. (read timeout=10.0)\\n\")\n"
     ]
    }
   ],
   "source": [
    "# Test v.0.3\n",
    "# Adding the Link to the response.\n",
    "altered_rag_chain = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=altered_rag_chain)\n",
    "\n",
    "result = rag_chain_with_source.invoke(\"What is Chemistry?\")\n",
    "\n",
    "# TODO: Optimize\n",
    "relevant_docs = set()\n",
    "for doc in result.get('context'):\n",
    "    relevant_docs.add(doc.metadata.get('source'))\n",
    "\n",
    "print(f\"Answer:\\n\\n{result.get('answer')}\\n\\nDISCLAIMER: LLM Generated Summary. Summary is generated from the sources seen below.\\n{list(relevant_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b94d4c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 10.13 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "300 ms ± 281 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "(Document(page_content='Syllabus\\n        \\n        \\n      \\n\\n Table of Contents\\n        \\n        \\n      \\n\\nSyllabus \\nLogistics\\nCourse Content and Format \\nLectures\\n3 Programming Assignments (PAs)\\nExams\\nScribe notes\\nReading Summary\\nParticipation\\n\\n\\nPre-requisites\\nGrading \\nComponents\\nCutoffs\\n\\n\\nClassroom Rules\\n\\n\\n\\nThe course is organized into four parts, covering the following topics.\\n\\nFoundations of Data Systems: Data models, big data storage and retrieval, and how to encode information when you store data.\\nScaling Distributed Systems: Cluster, cloud, edge, network, replication, partition, consistency, ACID.\\nData Processing and Programming model: Batch processing, stream processing, MapReduce, Hadoop, Spark, Ray.\\nMachine Learning Systems: GPUs, TensorFlow, PyTorch, data and model parallelism, LLM training and serving.', metadata={'source': 'https://hao-ai-lab.github.io/dsc204a-w24/syllabus/'}), 0.5019729137420654)\n",
      "\n",
      "\n",
      "(Document(page_content='A major component of this course is hands-on Python programming to implement data exploration, data preparation, distributed deep learning training and inference, and model selection pipelines on large real-world data using popular libraries (e.g., Ray, PyTorch) and cloud resources (e.g., AWS/GCP).\\n\\n Logistics\\n        \\n        \\n      \\n\\nLectures: MWF 10:00 AM - 10:50 AM.\\nLocation: PCYNH 122.\\nInstructor: Hao Zhang; Office: HDSI 440.\\n\\n\\n Course Content and Format\\n        \\n        \\n      \\n\\n Lectures\\n        \\n        \\n      \\nThe class meets 3 times a week for 50-minute lectures in person.', metadata={'source': 'https://hao-ai-lab.github.io/dsc204a-w24/syllabus/'}), 0.5132059454917908)\n",
      "\n",
      "\n",
      "(Document(page_content='Exams\\n        \\n        \\n      \\n\\nTo make your life easier: There is NO midterm. As an alternative, we ask for scribe notes and reading summary.\\nThere will be a final exam. The final exam will be held as a Canvas Quiz.\\nTentative date: Friday, March 22, 8 - 11 am, PT.\\nThe exams will have primarily multiple choice questions (MCQ). Quantitative/longer problems wil exist but only the final answer may need to be selected. Some questions will have partial credits.\\nThe guideline for time per question is a max of 1min per point. The points of each question will be calibrated accordingly.\\nIf you miss an exam, you will get no credit for it, unless you notify the instructor in advance with a university approved reason and receive a makeup exam slot.\\nThe final exam is open books/Web/etc. The only requirement is you should neither give nor receive help from anyone by any means.', metadata={'source': 'https://hao-ai-lab.github.io/dsc204a-w24/syllabus/'}), 0.5167027711868286)\n",
      "\n",
      "\n",
      "(Document(page_content='Course Content and Format\\n        \\n        \\n      \\n\\n Lectures\\n        \\n        \\n      \\nThe class meets 3 times a week for 50-minute lectures in person.\\n\\nAttending the lectures is not mandatory but highly encouraged. All lectures will be automatically podcast here afterward.\\nThere will be scribe notes required for each lecture. Students should form groups of 2 - 4 people and sign up one slot. See details below.\\nThere will be reading summary required per week. Everyone needs to submit their reading summary. See details below.\\nWe will use Piazza for asynchronous discussions and questions.\\n\\n\\n 3 Programming Assignments (PAs)\\n        \\n        \\n      \\n\\nSee the assignments page for updates on the PA schedule and details.\\nThere are no late days for the PAs. Plan your work accordingly.\\n\\n\\n Exams', metadata={'source': 'https://hao-ai-lab.github.io/dsc204a-w24/syllabus/'}), 0.5283002853393555)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%timeit vectorstore.similarity_search_with_score(\"What is Chemistry?\")\n",
    "\n",
    "similar_docs = vectorstore.similarity_search_with_score(\"What is Chemistry?\")\n",
    "for doc in similar_docs:\n",
    "    print(doc)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a3b509",
   "metadata": {},
   "source": [
    "<b>Assessment:</b><br>\n",
    "<ul>\n",
    "    <li> - LLM Method: Prompt may need to be adjusted. The LLM seems to be returning an answer. One-shot prompt?\n",
    "    <li> + Similarity score seems to be higher for the documents when the prompt is not related.\n",
    "    <li> - How to go about setting a threshold? Discuss this with the Prof. \n",
    "</ul>\n",
    "<b>Possible Adjustment:</b><br> \n",
    "<ul>\n",
    "    <li> Research Maximal Marginal Relevance(MMR) to potential improve the similarity check.\n",
    "    <li> Research other methods for document similarity check in this context, TF-IDF? Doc2Vec?\n",
    "    <li> Research different Embedding methods. MTEB leaderboard? \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da79c137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d677ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6faa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
